{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a link between the morphology in the\n",
    "[Openscriptures](http://openscriptures.org)\n",
    "and the linguistics in the [BHSA](https://github.com/ETCBC/bhsa).\n",
    "\n",
    "We proceed as follows:\n",
    "\n",
    "* extract the morphology from the files in\n",
    "  [openscriptures/morphhb/wlc](https://github.com/openscriptures/morphhb/tree/master/wlc)\n",
    "* link the words in the openscripture files to slots in the BHSA\n",
    "* compile the openscripture morphology data into a TF feature file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from lxml import etree\n",
    "from itertools import zip_longest\n",
    "from unicodedata import normalize, category\n",
    "\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.1.1\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.21s B g_cons_utf8          from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.78s T g_prs_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s Feature overview: 108 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  5.85s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "REPO = os.path.expanduser('~/github/etcbc/bhsa')\n",
    "baseDir = '{}/tf'.format(REPO)\n",
    "tempDir = '{}/_temp'.format(REPO)\n",
    "VERSION = '2017'\n",
    "\n",
    "TF = Fabric(locations='{}/tf/{}'.format(REPO, VERSION), modules=[''])\n",
    "api = TF.load('book g_cons_utf8 g_prs_utf8')\n",
    "api.makeAvailableIn(globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amos\n",
      "Canticum\n",
      "Chronica_I\n",
      "Chronica_II\n",
      "Daniel\n",
      "Deuteronomium\n",
      "Ecclesiastes\n",
      "Esra\n",
      "Esther\n",
      "Exodus\n",
      "Ezechiel\n",
      "Genesis\n",
      "Habakuk\n",
      "Haggai\n",
      "Hosea\n",
      "Iob\n",
      "Jeremia\n",
      "Jesaia\n",
      "Joel\n",
      "Jona\n",
      "Josua\n",
      "Judices\n",
      "Leviticus\n",
      "Maleachi\n",
      "Micha\n",
      "Nahum\n",
      "Nehemia\n",
      "Numeri\n",
      "Obadia\n",
      "Proverbia\n",
      "Psalmi\n",
      "Reges_I\n",
      "Reges_II\n",
      "Ruth\n",
      "Sacharia\n",
      "Samuel_I\n",
      "Samuel_II\n",
      "Threni\n",
      "Zephania\n"
     ]
    }
   ],
   "source": [
    "bhsBooks = sorted(F.book.v(n) for n in F.otype.s('book'))\n",
    "print('\\n'.join(bhsBooks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading open scriptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_BASE = os.path.expanduser('~/github/openscriptures/morphhb/wlc')\n",
    "os.chdir(OS_BASE)\n",
    "osBookSet = set(fn[0:-4] for fn in glob('*.xml') if fn != 'VerseMap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Chr\n",
      "1Kgs\n",
      "1Sam\n",
      "2Chr\n",
      "2Kgs\n",
      "2Sam\n",
      "Amos\n",
      "Dan\n",
      "Deut\n",
      "Eccl\n",
      "Esth\n",
      "Exod\n",
      "Ezek\n",
      "Ezra\n",
      "Gen\n",
      "Hab\n",
      "Hag\n",
      "Hos\n",
      "Isa\n",
      "Jer\n",
      "Job\n",
      "Joel\n",
      "Jonah\n",
      "Josh\n",
      "Judg\n",
      "Lam\n",
      "Lev\n",
      "Mal\n",
      "Mic\n",
      "Nah\n",
      "Neh\n",
      "Num\n",
      "Obad\n",
      "Prov\n",
      "Ps\n",
      "Ruth\n",
      "Song\n",
      "Zech\n",
      "Zeph\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(sorted(osBookSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "osBooks = '''\n",
    "Amos\n",
    "Song\n",
    "1Chr\n",
    "2Chr\n",
    "Dan\n",
    "Deut\n",
    "Eccl\n",
    "Esth\n",
    "Exod\n",
    "Ezek\n",
    "Ezra\n",
    "Gen\n",
    "Hab\n",
    "Hag\n",
    "Hos\n",
    "Job\n",
    "Isa\n",
    "Jer\n",
    "Joel\n",
    "Jonah\n",
    "Josh\n",
    "Judg\n",
    "Lev\n",
    "Mal\n",
    "Mic\n",
    "Nah\n",
    "Neh\n",
    "Num\n",
    "Obad\n",
    "Prov\n",
    "Ps\n",
    "1Kgs\n",
    "2Kgs\n",
    "Ruth\n",
    "Zech\n",
    "1Sam\n",
    "2Sam\n",
    "Lam\n",
    "Zeph\n",
    "'''.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "osBookFromBhs = {}\n",
    "bhsBookFromOs = {}\n",
    "for (i, bhsBook) in enumerate(bhsBooks):\n",
    "    osBook = osBooks[i]\n",
    "    osBookFromBhs[bhsBook] = osBook\n",
    "    bhsBookFromOs[osBook] = bhsBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS = '{http://www.bibletechnologies.net/2003/OSIS/namespace}'\n",
    "NFD = 'NFD'\n",
    "LO = 'Lo'\n",
    "\n",
    "finals = {\n",
    "    'ך':\\\n",
    "    'כ',\n",
    "    'ם':\\\n",
    "    'מ',\n",
    "    'ן':\\\n",
    "    'נ',\n",
    "    'ף':\\\n",
    "    'פ',\n",
    "    'ץ':\\\n",
    "    'צ',\n",
    "}\n",
    "\n",
    "finalsI = {v: k for (k,v) in finals.items()}\n",
    "\n",
    "# k\t05DA\tך\tletter final kaf\n",
    "# K\t05DB\tכ\tletter kaf\n",
    "# m\t05DD\tם\tletter final mem\n",
    "# M\t05DE\tמ\tletter mem\n",
    "# n\t05DF\tן\tletter final nun\n",
    "# N\t05E0\tנ\tletter nun\n",
    "# p\t05E3\tף\tletter final pe\n",
    "# P\t05E4\tפ\tletter pe\n",
    "# y\t05E5\tץ\tletter final tsadi\n",
    "# Y\t05E6\tצ\tletter tsadi\n",
    "\n",
    "\n",
    "def toCons(fw): return ''.join(c for c in normalize(NFD, fw) if category(c) == LO)\n",
    "def final(c): return finalsI.get(c, c)\n",
    "def finalCons(s): return s[0:-1]+final(s[-1])\n",
    "\n",
    "def readOsBook(osBook, osWords, stats):\n",
    "    infile = '{}.xml'.format(osBook)\n",
    "    parser = etree.XMLParser(remove_blank_text=True, ns_clean=True)\n",
    "    root = etree.parse(infile, parser).getroot()\n",
    "    osisTextNode = root[0]\n",
    "    divNode = osisTextNode[1]\n",
    "    chapterNodes = list(divNode)\n",
    "    print('reading {:<5} ({:<15}) {:>3} chapters'.format(osBook, bhsBookFromOs[osBook], len(chapterNodes)))\n",
    "    for chapterNode in chapterNodes:\n",
    "        if chapterNode.tag != NS+'chapter': continue\n",
    "        for verseNode in list(chapterNode):\n",
    "            if verseNode.tag != NS+'verse': continue\n",
    "            for wordNode in list(verseNode):\n",
    "                if wordNode.tag != NS+'w': continue\n",
    "                lemma = wordNode.get('lemma', None)\n",
    "                morph = wordNode.get('morph', None)\n",
    "                text = wordNode.text\n",
    "                lemmas = lemma.split('/') if lemma != None else []\n",
    "                morphs = morph.split('/') if morph != None else []\n",
    "                texts = text.split('/') if text != None else []\n",
    "                for (lm, mph, tx) in zip_longest(lemmas, morphs, texts):\n",
    "                    txc = None if tx == None else toCons(tx)\n",
    "                    osWords.append((tx, txc, mph, lm))\n",
    "                    if mph == None:\n",
    "                        stats['noMorph'] += 1\n",
    "                    if tx == None:\n",
    "                        stats['xMorph'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Gen   (Genesis        )  50 chapters\n",
      "reading Ezek  (Exodus         )  48 chapters\n",
      "reading Lev   (Leviticus      )  27 chapters\n",
      "reading Num   (Numeri         )  36 chapters\n",
      "reading Deut  (Deuteronomium  )  34 chapters\n",
      "reading Josh  (Josua          )  24 chapters\n",
      "reading Judg  (Judices        )  21 chapters\n",
      "reading 1Sam  (Samuel_I       )  31 chapters\n",
      "reading 2Sam  (Samuel_II      )  24 chapters\n",
      "reading 1Kgs  (Reges_I        )  22 chapters\n",
      "reading 2Kgs  (Reges_II       )  25 chapters\n",
      "reading Jer   (Jesaia         )  52 chapters\n",
      "reading Isa   (Jeremia        )  66 chapters\n",
      "reading Ezra  (Ezechiel       )  10 chapters\n",
      "reading Hos   (Hosea          )  14 chapters\n",
      "reading Joel  (Joel           )   4 chapters\n",
      "reading Amos  (Amos           )   9 chapters\n",
      "reading Obad  (Obadia         )   1 chapters\n",
      "reading Jonah (Jona           )   4 chapters\n",
      "reading Mic   (Micha          )   7 chapters\n",
      "reading Nah   (Nahum          )   3 chapters\n",
      "reading Hab   (Habakuk        )   3 chapters\n",
      "reading Zeph  (Zephania       )   3 chapters\n",
      "reading Hag   (Haggai         )   2 chapters\n",
      "reading Zech  (Sacharia       )  14 chapters\n",
      "reading Mal   (Maleachi       )   3 chapters\n",
      "reading Ps    (Psalmi         ) 150 chapters\n",
      "reading Job   (Iob            )  42 chapters\n",
      "reading Prov  (Proverbia      )  31 chapters\n",
      "reading Ruth  (Ruth           )   4 chapters\n",
      "reading Song  (Canticum       )   8 chapters\n",
      "reading Eccl  (Ecclesiastes   )  12 chapters\n",
      "reading Lam   (Threni         )   5 chapters\n",
      "reading Exod  (Esther         )  40 chapters\n",
      "reading Dan   (Daniel         )  12 chapters\n",
      "reading Esth  (Esra           )  10 chapters\n",
      "reading Neh   (Nehemia        )  13 chapters\n",
      "reading 1Chr  (Chronica_I     )  29 chapters\n",
      "reading 2Chr  (Chronica_II    )  36 chapters\n",
      "\n",
      "BHS words:       426584\n",
      "Collected words: 469448\n",
      "No morphology:    54875\n",
      "Mismatches:          17\n",
      "88 % of the words are morphologically annotated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "osWords = []\n",
    "stats = dict(noMorph=0, xMorph=0)\n",
    "\n",
    "for bn in F.otype.s('book'):\n",
    "    bhsBook = T.sectionFromNode(bn, lang='la')[0]\n",
    "    osBook = osBookFromBhs[bhsBook]\n",
    "    readOsBook(osBook, osWords, stats)\n",
    "\n",
    "print('''\n",
    "BHS words:       {:>6}\n",
    "Collected words: {:>6}\n",
    "No morphology:   {:>6}\n",
    "Mismatches:      {:>6}\n",
    "{} % of the words are morphologically annotated.\n",
    "'''.format(\n",
    "        F.otype.maxSlot,\n",
    "        len(osWords),\n",
    "        stats['noMorph'], \n",
    "        stats['xMorph'], \n",
    "        round(100 * (len(osWords) - stats['noMorph'] - stats['xMorph'])/len(osWords)),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('בְּ', 'ב', 'HR', 'b')),\n",
       " (1, ('רֵאשִׁ֖ית', 'ראשית', 'Ncfsa', '7225')),\n",
       " (2, ('בָּרָ֣א', 'ברא', 'HVqp3ms', '1254 a')),\n",
       " (3, ('אֱלֹהִ֑ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (4, ('אֵ֥ת', 'את', 'HTo', '853')),\n",
       " (5, ('הַ', 'ה', 'HTd', 'd')),\n",
       " (6, ('שָּׁמַ֖יִם', 'שמים', 'Ncmpa', '8064')),\n",
       " (7, ('וְ', 'ו', 'HC', 'c')),\n",
       " (8, ('אֵ֥ת', 'את', 'To', '853')),\n",
       " (9, ('הָ', 'ה', 'HTd', 'd')),\n",
       " (10, ('אָֽרֶץ', 'ארץ', 'Ncbsa', '776')),\n",
       " (11, ('וְ', 'ו', 'HC', 'c')),\n",
       " (12, ('הָ', 'ה', 'Td', 'd')),\n",
       " (13, ('אָ֗רֶץ', 'ארץ', 'Ncbsa', '776')),\n",
       " (14, ('הָיְתָ֥ה', 'היתה', 'HVqp3fs', '1961')),\n",
       " (15, ('תֹ֨הוּ֙', 'תהו', 'HNcmsa', '8414')),\n",
       " (16, ('וָ', 'ו', 'HC', 'c')),\n",
       " (17, ('בֹ֔הוּ', 'בהו', 'Ncmsa', '922')),\n",
       " (18, ('וְ', 'ו', 'HC', 'c')),\n",
       " (19, ('חֹ֖שֶׁךְ', 'חשך', 'Ncmsa', '2822')),\n",
       " (20, ('עַל', 'על', 'HR', '5921 a')),\n",
       " (21, ('פְּנֵ֣י', 'פני', 'HNcbpc', '6440')),\n",
       " (22, ('תְה֑וֹם', 'תהום', 'HNcbsa', '8415')),\n",
       " (23, ('וְ', 'ו', 'HC', 'c')),\n",
       " (24, ('ר֣וּחַ', 'רוח', 'Ncbsc', '7307')),\n",
       " (25, ('אֱלֹהִ֔ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (26, ('מְרַחֶ֖פֶת', 'מרחפת', 'HVprfsa', '7363 b')),\n",
       " (27, ('עַל', 'על', 'HR', '5921 a')),\n",
       " (28, ('פְּנֵ֥י', 'פני', 'HNcbpc', '6440')),\n",
       " (29, ('הַ', 'ה', 'HTd', 'd')),\n",
       " (30, ('מָּֽיִם', 'מים', 'Ncmpa', '4325')),\n",
       " (31, ('וַ', 'ו', 'HC', 'c')),\n",
       " (32, ('יֹּ֥אמֶר', 'יאמר', 'Vqw3ms', '559')),\n",
       " (33, ('אֱלֹהִ֖ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (34, ('יְהִ֣י', 'יהי', 'HVqj3ms', '1961')),\n",
       " (35, ('א֑וֹר', 'אור', 'HNcbsa', '216')),\n",
       " (36, ('וַֽ', 'ו', 'HC', 'c')),\n",
       " (37, ('יְהִי', 'יהי', 'Vqw3ms', '1961')),\n",
       " (38, ('אֽוֹר', 'אור', 'HNcbsa', '216')),\n",
       " (39, ('וַ', 'ו', 'HC', 'c')),\n",
       " (40, ('יַּ֧רְא', 'ירא', 'Vqw3ms', '7200')),\n",
       " (41, ('אֱלֹהִ֛ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (42, ('אֶת', 'את', 'HTo', '853')),\n",
       " (43, ('הָ', 'ה', 'HTd', 'd')),\n",
       " (44, ('א֖וֹר', 'אור', 'Ncbsa', '216')),\n",
       " (45, ('כִּי', 'כי', 'HC', '3588 a')),\n",
       " (46, ('ט֑וֹב', 'טוב', None, '2896 a')),\n",
       " (47, ('וַ', 'ו', 'HC', 'c')),\n",
       " (48, ('יַּבְדֵּ֣ל', 'יבדל', 'Vhw3ms', '914')),\n",
       " (49, ('אֱלֹהִ֔ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (50, ('בֵּ֥ין', 'בין', 'HR', '996')),\n",
       " (51, ('הָ', 'ה', 'HTd', 'd')),\n",
       " (52, ('א֖וֹר', 'אור', 'Ncbsa', '216')),\n",
       " (53, ('וּ', 'ו', 'HC', 'c')),\n",
       " (54, ('בֵ֥ין', 'בין', 'R', '996')),\n",
       " (55, ('הַ', 'ה', 'HTd', 'd')),\n",
       " (56, ('חֹֽשֶׁךְ', 'חשך', 'Ncmsa', '2822')),\n",
       " (57, ('וַ', 'ו', 'HC', 'c')),\n",
       " (58, ('יִּקְרָ֨א', 'יקרא', 'Vqw3ms', '7121')),\n",
       " (59, ('אֱלֹהִ֤ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (60, ('לָ', 'ל', 'HRd', 'l')),\n",
       " (61, ('אוֹר֙', 'אור', 'Ncbsa', '216')),\n",
       " (62, ('י֔וֹם', 'יום', 'HNcmsa', '3117')),\n",
       " (63, ('וְ', 'ו', 'HC', 'c')),\n",
       " (64, ('לַ', 'ל', 'Rd', 'l')),\n",
       " (65, ('חֹ֖שֶׁךְ', 'חשך', 'Ncmsa', '2822')),\n",
       " (66, ('קָ֣רָא', 'קרא', 'HVqp3ms', '7121')),\n",
       " (67, ('לָ֑יְלָה', 'לילה', 'HNcmsa', '3915')),\n",
       " (68, ('וַֽ', 'ו', 'HC', 'c')),\n",
       " (69, ('יְהִי', 'יהי', 'Vqw3ms', '1961')),\n",
       " (70, ('עֶ֥רֶב', 'ערב', 'HNcmsa', '6153')),\n",
       " (71, ('וַֽ', 'ו', 'HC', 'c')),\n",
       " (72, ('יְהִי', 'יהי', 'Vqw3ms', '1961')),\n",
       " (73, ('בֹ֖קֶר', 'בקר', 'HNcmsa', '1242')),\n",
       " (74, ('י֥וֹם', 'יום', 'HNcmsa', '3117')),\n",
       " (75, ('אֶחָֽד', 'אחד', 'HAcmsa', '259')),\n",
       " (76, ('וַ', 'ו', 'HC', 'c')),\n",
       " (77, ('יֹּ֣אמֶר', 'יאמר', 'Vqw3ms', '559')),\n",
       " (78, ('אֱלֹהִ֔ים', 'אלהים', 'HNcmpa', '430')),\n",
       " (79, ('יְהִ֥י', 'יהי', 'HVqj3ms', '1961')),\n",
       " (80, ('רָקִ֖יעַ', 'רקיע', 'HNcmsa', '7549')),\n",
       " (81, ('בְּ', 'ב', 'HR', 'b')),\n",
       " (82, ('ת֣וֹךְ', 'תוך', 'Ncmsc', '8432')),\n",
       " (83, ('הַ', 'ה', 'HTd', 'd')),\n",
       " (84, ('מָּ֑יִם', 'מים', 'Ncmpa', '4325')),\n",
       " (85, ('וִ', 'ו', 'HC', 'c')),\n",
       " (86, ('יהִ֣י', 'יהי', 'Vqi3ms', '1961')),\n",
       " (87, ('מַבְדִּ֔יל', 'מבדיל', 'HVhrmsa', '914')),\n",
       " (88, ('בֵּ֥ין', 'בין', 'HR', '996')),\n",
       " (89, ('מַ֖יִם', 'מים', 'HNcmpa', '4325')),\n",
       " (90, ('לָ', 'ל', 'HR', 'l')),\n",
       " (91, ('מָֽיִם', 'מים', 'Ncmpa', '4325')),\n",
       " (92, ('וַ', 'ו', 'HC', 'c')),\n",
       " (93, ('יַּ֣עַשׂ', 'יעש', 'Vqw3ms', '6213 a')),\n",
       " (94, ('אֱלֹהִים֮', 'אלהים', 'HNcmpa', '430')),\n",
       " (95, ('אֶת', 'את', 'HTo', '853')),\n",
       " (96, ('הָ', 'ה', 'HTd', 'd')),\n",
       " (97, ('רָקִיעַ֒', 'רקיע', 'Ncmsa', '7549')),\n",
       " (98, ('וַ', 'ו', 'HC', 'c')),\n",
       " (99, ('יַּבְדֵּ֗ל', 'יבדל', 'Vhw3ms', '914'))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(osWords[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there 40,000 word more in OS than in BHSA?\n",
    "Let's explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at 61: bhs=[] os=[אור]\n"
     ]
    }
   ],
   "source": [
    "for (i, w) in enumerate(F.otype.s('word')):\n",
    "    bhs = toCons(F.g_cons_utf8.v(w))\n",
    "    os = toCons(osWords[i][0])\n",
    "    if bhs != os:\n",
    "        print('Mismatch at {}: bhs=[{}] os=[{}]'.format(i, bhs, os))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 ל\n",
      "62 \n",
      "63 אור\n",
      "64 יום\n"
     ]
    }
   ],
   "source": [
    "for i in range(61,65):\n",
    "    print(i, F.g_cons_utf8.v(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, the BHSA has encoded an empty article here, because the pointing of surrounding letters signals an article.\n",
    "So let's ignore the inserted empty articles of the BHSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at BHS-194 OS-187:\n",
      "bhs=[מינו]\n",
      "os=[מינ]\n"
     ]
    }
   ],
   "source": [
    "j = -1\n",
    "for w in F.otype.s('word'):\n",
    "    bhs = toCons(F.g_cons_utf8.v(w))\n",
    "    if bhs == '': continue\n",
    "    j += 1\n",
    "    os = osWords[j][1]\n",
    "    if bhs != os:\n",
    "        print('''Mismatch at BHS-{} OS-{}:\\nbhs=[{}]\\nos=[{}]'''.format(w, j, bhs, os))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 פרי פרי\n",
      "193 ל ל\n",
      "194 מינו מינ\n",
      "195 אשר ו\n"
     ]
    }
   ],
   "source": [
    "for w in range(192,196):\n",
    "    print(w, toCons(F.g_cons_utf8.v(w)), osWords[w-7][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, the BHS does not split a word here, while the OS does, or rather: the OS specifies a morpheme boundary here.\n",
    "Maybe we can remedy this by looking at the pronominal suffix in the BHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at BHS-988 OS-1012:\n",
      "bhs=[ממנ]\n",
      "os=[ממ]\n"
     ]
    }
   ],
   "source": [
    "j = -1\n",
    "bhsPrs = {}\n",
    "for w in F.otype.s('word'):\n",
    "    bhs = toCons(F.g_cons_utf8.v(w))\n",
    "    if bhs == '': continue\n",
    "    j += 1\n",
    "    os = osWords[j][1]\n",
    "    prs = F.g_prs_utf8.v(w)\n",
    "    if prs:\n",
    "        cprs = toCons(prs.strip())\n",
    "        fcprs = finalCons(cprs)\n",
    "        if bhs.endswith(cprs) or bhs.endswith(fcprs):\n",
    "            bhs = bhs[0:len(bhs)-len(cprs)]\n",
    "    if bhs != os:\n",
    "        print('''Mismatch at BHS-{} OS-{}:\\nbhs=[{}]\\nos=[{}]'''.format(w, j, bhs, os))\n",
    "        break\n",
    "    if prs:\n",
    "        j += 1\n",
    "        os = osWords[j][1]\n",
    "        bhs = fcprs\n",
    "        if bhs != os:\n",
    "            print('''Mismatch in prs of BHS-{} OS-{}:\\nbhs=[{}]\\nos=[{}]'''.format(w, j, bhs, os))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988 ממנו ממ\n",
      "989 כי נו\n"
     ]
    }
   ],
   "source": [
    "for w in range(988,990):\n",
    "    print(w, toCons(F.g_cons_utf8.v(w)), osWords[w+24][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ו'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toCons(F.g_prs_utf8.v(988))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ממנו'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toCons(F.g_cons_utf8.v(988))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "לא\n",
      "תאכל\n",
      "ממ\n",
      "נו\n",
      "כי\n"
     ]
    }
   ],
   "source": [
    "for i in range(1010,1015): print(osWords[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Genesis', 2, 17)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sectionFromNode(988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
